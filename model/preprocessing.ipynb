{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import warnings\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"D:/sl_dataset/\"\n",
    "\n",
    "video_src = os.path.join(base_dir, \"source\")\n",
    "keypoints_src = os.path.join(base_dir, \"keypoints\")\n",
    "\n",
    "# mediapipe pose model init / mediapipe pose model 선언\n",
    "mp_pose = mp.solutions.pose\n",
    "pose_model = mp_pose.Pose(static_image_mode=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(keypoints_list):\n",
    "    max_length = 0  # val of max keypoints length / 키포인트 최대 길이값\n",
    "    for keypoints_data in keypoints_list:\n",
    "        current_length = keypoints_data.shape[0]    # keypoints length / 현재 keypoints의 길이값\n",
    "        if current_length > max_length:\n",
    "            max_length = current_length\n",
    "    print(f\"Max length : {max_length}\")    \n",
    "    return int(max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pose_keypoints(video_src, pose_model):\n",
    "    pose_keypoints_list = []\n",
    "    filename_list = []\n",
    "\n",
    "    for video_file in tqdm(os.listdir(video_src)):\n",
    "        video_path = os.path.join(video_src, video_file)  # generate file path / 파일 경로 생성\n",
    "        filename = os.path.splitext(video_file)[0]  # filename remove extension / 파일 이름(확장자 제거)\n",
    "        cap = cv2.VideoCapture(video_path)  # video load / 영상 읽어오기\n",
    "        pose_keypoints = []  # list of pose keypoints / pose 키포인트를 저장할 리스트\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()  # opened, frame read from video / 읽기 여부 프레임 읽기\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            results = pose_model.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))  # pose process / pose 키포인트 추출 프로세스\n",
    "            if results.pose_landmarks:\n",
    "                keypoints = [[lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark]  # x, y, z\n",
    "                pose_keypoints.append(keypoints)\n",
    "        cap.release()\n",
    "\n",
    "        keypoints_array = np.array(pose_keypoints)  # list to npy / 리스트 => numpy ndarray 변환\n",
    "        pose_keypoints_list.append(keypoints_array)  # list of extracted keypoints data / 추출된 pose keypoints를 저장할 리스트\n",
    "        filename_list.append(filename)  # filename added to list / 파일 이름을 리스트에 추가\n",
    "\n",
    "    match_df = pd.DataFrame({\n",
    "        'filename': filename_list,  # Filename list / 파일 이름 리스트\n",
    "        'pose_keypoints': pose_keypoints_list  # Pose keypoints list / 포즈 키포인트 리스트\n",
    "    })\n",
    "\n",
    "    return match_df  # Return DataFrame / DataFrame 반환\n",
    "\n",
    "match_df = extract_pose_keypoints(video_src, pose_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length : 165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:00<00:00, 2143.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KETI_SL_0000000001 - (165, 33, 3)\n",
      "KETI_SL_0000000002 - (165, 33, 3)\n",
      "KETI_SL_0000000003 - (165, 33, 3)\n",
      "KETI_SL_0000000004 - (165, 33, 3)\n",
      "KETI_SL_0000000005 - (165, 33, 3)\n",
      "KETI_SL_0000000006 - (165, 33, 3)\n",
      "KETI_SL_0000000007 - (165, 33, 3)\n",
      "KETI_SL_0000000008 - (165, 33, 3)\n",
      "KETI_SL_0000000009 - (165, 33, 3)\n",
      "KETI_SL_0000000010 - (165, 33, 3)\n",
      "KETI_SL_0000000011 - (165, 33, 3)\n",
      "KETI_SL_0000000012 - (165, 33, 3)\n",
      "KETI_SL_0000000013 - (165, 33, 3)\n",
      "KETI_SL_0000000014 - (165, 33, 3)\n",
      "KETI_SL_0000000015 - (165, 33, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_length = get_max_length(match_df['pose_keypoints'])\n",
    "\n",
    "for i, keypoints_data in enumerate(tqdm(match_df['pose_keypoints'])):\n",
    "    filename = match_df['filename'][i]  # corrected indexing / 인덱싱 수정\n",
    "    current_length = keypoints_data.shape[0]\n",
    "\n",
    "    if max_length > current_length:\n",
    "        padding = np.zeros((max_length - current_length, 33, 3))\n",
    "        padded_keypoints = np.vstack((keypoints_data, padding))\n",
    "    else:\n",
    "        padded_keypoints = keypoints_data\n",
    "\n",
    "    np.save(keypoints_src + f\"/{filename}_padded.npy\", padded_keypoints)\n",
    "    print(f\"{filename} - {padded_keypoints.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
